import 'dotenv/config';
import {
    DeepgramService,
    OpenAIService,
    CartesiaService,
    Pipeline,
    ContextManager
} from '../src/index.js';
import playSound from 'play-sound';
import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Track current audio playback
let currentAudio: any = null;

// Define our function tools
const functionTools = [{
    name: "log_banana_mention",
    description: "Log when someone talks about bananas",
    parameters: {
        type: "object",
        properties: {
            message: {
                type: "string",
                description: "The message containing banana-related content"
            }
        },
        required: ["message"]
    }
},
{
    name: "log_apple_mention",
    description: "Log when someone talks about apples",
    parameters: {
        type: "object",
        properties: {
            message: {
                type: "string",
                description: "The message containing apple-related content"
            }
        },
        required: ["message"]
    }
}];

// Define our function handlers
const functionHandlers = {
    log_banana_mention: (args: { message: string }) => {
        console.log('üçå [BANANA MENTION]:', args.message);
    },
    log_apple_mention: (args: { message: string }) => {
        console.log('üçé [APPLE MENTION]:', args.message);
    }
};

async function main() {
    const player = playSound({});
    const contextManager = new ContextManager();
    
    // Initialize services
    const sttService = new DeepgramService(process.env.DEEPGRAM_API_KEY || '');

    const llmService = new OpenAIService(process.env.OPENAI_API_KEY || '', {
        model: "gpt-4",
        maxTokens: 100,
        systemPrompt: "You are a helpful AI assistant. When users mention bananas, use the log_banana_mention function. When users mention apples, use the log_apple_mention function.",
        tools: functionTools,
        functionHandlers: functionHandlers
    });

    const ttsService = new CartesiaService(process.env.CARTESIA_API_KEY || '', {
        model: "sonic-english"
    });

    // Create the pipeline
    const pipeline = new Pipeline(
        sttService,
        llmService,
        ttsService,
        {
            contextManager,
            vadConfig: {
                onSpeechStart: () => {
                    console.log('\nüé§ Started speaking...');
                },
                onSpeechEnd: () => {
                    console.log('üé§ Finished speaking');
                },
                onVADMisfire: () => {
                    console.log('‚ö†Ô∏è  False trigger detected');
                },
                onInterrupt: () => {
                    console.log('ü§ö Interrupting response...');
                    // Stop any currently playing audio
                    if (currentAudio) {
                        currentAudio.kill();
                        currentAudio = null;
                    }
                }
            },
            onTranscript: (text) => {
                console.log('\nüë§ You said:', text);
            },
            onResponse: (text) => {
                process.stdout.write(text);
            },
            onError: (error) => {
                console.error('\n‚ùå Error:', error.message);
            },
            onAudioReady: async (audio) => {
                try {
                    const tempFile = path.join(__dirname, `temp-${Date.now()}.wav`);
                    await fs.writeFile(tempFile, audio);

                    console.log('\nüîà Playing audio response...');
                    pipeline.setAudioPlayingState(true);
                    currentAudio = player.play(tempFile, (err?: Error) => {
                        pipeline.setAudioPlayingState(false);
                        if (err && err.message !== 'Killed') {
                            console.error('\n‚ùå Error playing audio:', err);
                        }
                        fs.unlink(tempFile).catch(err => {
                            console.error('\n‚ùå Error deleting temp file:', err);
                        });
                    });
                } catch (error) {
                    console.error('\n‚ùå Error handling audio:', error);
                    pipeline.setAudioPlayingState(false);
                }
            }
        }
    );

    console.log('üöÄ Initializing voice agent...');
    
    try {
        await pipeline.startVoiceChat();
        console.log('\n‚ú® Voice agent is ready!');
        console.log('üí° Start speaking, and I will respond.');
        console.log('üçé Try mentioning apples or bananas! üçå');
        console.log('‚å®Ô∏è  Press Ctrl+C to stop');
    } catch (error) {
        console.error('\n‚ùå Failed to start voice agent:', error);
        process.exit(1);
    }
}

main().catch((error) => {
    console.error('\n‚ùå Fatal error:', error);
    process.exit(1);
}); 