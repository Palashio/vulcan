/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as fs from "fs";
import { Blob } from "buffer";
import * as Cartesia from "../../../index";
import * as stream from "stream";
export declare namespace Infill {
    interface Options {
        environment?: core.Supplier<environments.CartesiaEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string | undefined>;
        /** Override the Cartesia-Version header */
        cartesiaVersion?: "2024-06-10";
        fetcher?: core.FetchFunction;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the Cartesia-Version header */
        cartesiaVersion?: "2024-06-10";
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}
export declare class Infill {
    protected readonly _options: Infill.Options;
    constructor(_options?: Infill.Options);
    /**
     * Generate audio that smoothly connects two existing audio segments. This is useful for inserting new speech between existing speech segments while maintaining natural transitions.
     *
     * **The cost is 1 credit per character of the infill text plus a fixed cost of 300 credits.**
     *
     * Only the `sonic-preview` model is supported for infill at this time.
     *
     * At least one of `left_audio` or `right_audio` must be provided.
     *
     * As with all generative models, there's some inherent variability, but here's some tips we recommend to get the best results from infill:
     * - Use longer infill transcripts
     *   - This gives the model more flexibility to adapt to the rest of the audio
     * - Target natural pauses in the audio when deciding where to clip
     *   - This means you don't need word-level timestamps to be as precise
     * - Clip right up to the start and end of the audio segment you want infilled, keeping as much silence in the left/right audio segments as possible
     *   - This helps the model generate more natural transitions
     */
    bytes(leftAudio: File | fs.ReadStream | Blob, rightAudio: File | fs.ReadStream | Blob, request: Cartesia.InfillBytesRequest, requestOptions?: Infill.RequestOptions): Promise<stream.Readable>;
    protected _getCustomAuthorizationHeaders(): Promise<{
        "X-API-Key": string | undefined;
    }>;
}
